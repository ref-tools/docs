---
title: 'Read URL Content'
description: 'Extract and process content from any URL'
---

## Endpoint

```
POST https://ref.tools/api/read-url
```

Extract and process content from any publicly accessible URL. Perfect for reading documentation pages, GitHub files, blog posts, and more.

## Request

### Headers

| Header | Value |
|--------|-------|
| `Authorization` | `Bearer YOUR_API_KEY` |
| `Content-Type` | `application/json` |

### Body Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `url` | string | Yes | URL to read and extract content from |
| `format` | string | No | Output format: `markdown`, `html`, `text` (default: `markdown`) |
| `extractLinks` | boolean | No | Extract links from the content (default: `false`) |

### Example Request

```bash
curl -X POST https://ref.tools/api/read-url \
  -H "Authorization: Bearer ref_api_1234567890abcdef" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://react.dev/reference/react/useState",
    "format": "markdown",
    "extractLinks": true
  }'
```

## Response

### Success Response (200)

```json
{
  "url": "https://react.dev/reference/react/useState",
  "title": "useState â€“ React",
  "content": "# useState\n\n`useState` is a React Hook that lets you add a state variable to your component...",
  "metadata": {
    "description": "useState Hook documentation",
    "keywords": ["react", "hooks", "state"],
    "lastModified": "2024-01-15T10:30:00Z",
    "author": "React Team",
    "language": "en"
  },
  "links": [
    "https://react.dev/learn/state-a-components-memory",
    "https://react.dev/reference/react/useReducer"
  ],
  "creditsUsed": 1,
  "requestId": "req_read_12345"
}
```

### Error Responses

#### 400 Bad Request

```json
{
  "error": "invalid_url",
  "message": "The provided URL is not valid or accessible",
  "code": "INVALID_URL"
}
```

#### 404 Not Found

```json
{
  "error": "url_not_found",
  "message": "The URL could not be accessed",
  "code": "URL_NOT_FOUND"
}
```

#### 413 Content Too Large

```json
{
  "error": "content_too_large",
  "message": "The content at this URL is too large to process",
  "code": "CONTENT_TOO_LARGE",
  "maxSize": "10MB"
}
```

## SDK Examples

<CodeGroup>

```javascript JavaScript
import { RefClient } from '@ref-tools/js-sdk';

const client = new RefClient({ apiKey: 'your-api-key' });

const result = await client.readUrl({
  url: 'https://react.dev/reference/react/useState',
  format: 'markdown',
  extractLinks: true
});

console.log(result.title);
console.log(result.content);
console.log(result.links);
```

```python Python
from ref_tools import RefClient

client = RefClient(api_key='your-api-key')

result = client.read_url(
    url='https://react.dev/reference/react/useState',
    format='markdown',
    extract_links=True
)

print(result['title'])
print(result['content'])
print(result['links'])
```

```go Go
package main

import (
    "fmt"
    "github.com/ref-tools/go-sdk"
)

func main() {
    client := ref.NewClient("your-api-key")
    
    result, err := client.ReadURL(&ref.ReadURLRequest{
        URL: "https://react.dev/reference/react/useState",
        Format: "markdown",
        ExtractLinks: true,
    })
    
    if err != nil {
        panic(err)
    }
    
    fmt.Printf("Title: %s\n", result.Title)
    fmt.Printf("Content length: %d\n", len(result.Content))
}
```

</CodeGroup>

## Supported Content Types

### Web Pages
- HTML documents
- Documentation sites
- Blog posts
- News articles
- Technical guides

### Code Repositories
- GitHub README files
- GitLab documentation
- Bitbucket wikis
- Source code files (with syntax highlighting)

### Document Formats
- PDF files (text extraction)
- Markdown files
- Plain text files
- XML/RSS feeds

## Content Processing

### Text Extraction
- Removes navigation, ads, and boilerplate
- Preserves main content structure
- Maintains code formatting
- Extracts meaningful headings

### Format Options

<AccordionGroup>
  <Accordion title="Markdown (Default)">
    **Best for**: Documentation, technical content, structured text
    
    **Features**:
    - Preserves headings, lists, and formatting
    - Converts code blocks with syntax highlighting
    - Maintains link structure
    - Clean, readable output
  </Accordion>

  <Accordion title="HTML">
    **Best for**: Preserving original formatting, web scraping
    
    **Features**:
    - Retains original HTML structure
    - Preserves styling information
    - Includes metadata tags
    - Useful for further processing
  </Accordion>

  <Accordion title="Plain Text">
    **Best for**: Simple content extraction, text analysis
    
    **Features**:
    - Pure text content only
    - No formatting preserved
    - Smallest response size
    - Good for search indexing
  </Accordion>
</AccordionGroup>

## Use Cases

### Documentation Research
```bash
# Read API documentation
curl -X POST https://ref.tools/api/read-url \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://docs.python.org/3/library/asyncio.html",
    "format": "markdown"
  }'
```

### Code Analysis
```bash
# Read GitHub source files
curl -X POST https://ref.tools/api/read-url \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://raw.githubusercontent.com/facebook/react/main/packages/react/src/React.js",
    "format": "text"
  }'
```

### Content Aggregation
```bash
# Extract content with links for further processing
curl -X POST https://ref.tools/api/read-url \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://blog.example.com/react-best-practices",
    "format": "markdown",
    "extractLinks": true
  }'
```

## Limitations

### Content Size
- Maximum content size: **10MB**
- Large files may be truncated
- PDF processing limited to first 100 pages

### Access Restrictions
- Must be publicly accessible (no authentication required)
- Respects robots.txt when specified
- Some sites may block automated access
- Rate limiting may apply to source sites

### Supported Protocols
- **HTTPS** (recommended)
- **HTTP** (automatically upgraded to HTTPS when possible)
- **File URLs** not supported
- **Data URLs** not supported

## Best Practices

<CardGroup cols={2}>
  <Card title="URL Validation">
    - Verify URLs are accessible before calling API
    - Handle redirects appropriately
    - Check content type if known
    - Use canonical URLs when possible
  </Card>
  
  <Card title="Error Handling">
    - Implement retry logic for transient failures
    - Handle timeout errors gracefully
    - Check for content size limitations
    - Validate response format
  </Card>
  
  <Card title="Performance">
    - Cache results when appropriate
    - Use specific format for your use case
    - Only extract links when needed
    - Monitor credit usage
  </Card>
  
  <Card title="Content Processing">
    - Clean extracted content as needed
    - Validate markdown/HTML output
    - Handle special characters properly
    - Consider content freshness
  </Card>
</CardGroup>

## Troubleshooting

<AccordionGroup>
  <Accordion title="URL Not Accessible">
    **Problem**: Getting 404 or timeout errors
    
    **Solutions**:
    - Verify URL is correct and publicly accessible
    - Check if site requires specific headers
    - Try accessing URL in browser first
    - Check for typos in URL
  </Accordion>

  <Accordion title="Content Too Large">
    **Problem**: Content exceeds size limits
    
    **Solutions**:
    - Try linking to specific sections
    - Use text format for smaller response
    - Split large documents into smaller parts
    - Consider using search instead
  </Accordion>

  <Accordion title="Poor Content Quality">
    **Problem**: Extracted content is incomplete or malformed
    
    **Solutions**:
    - Try different output format
    - Check if site uses JavaScript rendering
    - Verify content type is supported
    - Use direct links to content sections
  </Accordion>
</AccordionGroup>

## Rate Limits & Credits

- **Credits**: 1 credit per request
- **Rate Limits**: Same as other API endpoints
- **Timeout**: 30 seconds maximum per request

## Related Endpoints

- [Search Documentation](/api-reference/endpoints/search) - Search through indexed content
- [Web Search](/api-reference/endpoints/web-search) - Real-time web search

Ready to start reading URLs? Get your API key from the [dashboard](https://ref.tools/dashboard) and try it out!